{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Привет Марк! Меня зовут Марат, и я буду твоим ревьюером. Спешу сообщить что все ключевые этапы в работе выполнены,  с задачей тебе удалось справиться. По поводу обращения - в IT сфере принято общаться на «ты» :) Но, если привычней на «вы», дай знать. Как ревьюера моя задача помочь тебе в развитии, дав хорошие советы. Я внимательно посмотрю твой код, ознакомлюсь с твоими выводами и оставлю комментарии. Где то могу предложить небольшие исправление в коде, но ненавязчиво. Где потребуются уточнения, я оставлю много наводящих вопросов. Они помогут тебя с поиском верного решения.\n",
    "\n",
    "Все мои комментарии размечены по цветам, для лучшего восприятия. \n",
    "    \n",
    "<div class=\"alert alert-success\">Зеленым цветом и словом «Успех» отмечены особо удачные и элегантные решения, которыми ты можешь гордиться. </div>\n",
    "        \n",
    "<div class=\"alert alert-warning\">Желтым и значком словом «Совет», помечены решения у которых есть альтернативные решения, более оптимальные. Ты можешь найти их сразу и доработать проект, или отложить это на потом, для будущих проектах. Проект будет принят и без их доработки. </div>\n",
    "        \n",
    "<div class=\"alert alert-danger\"> Красным цветом и значком словом «Ошибка» помечу твои решения, на которые стоит обратить внимание прежде всего. После их доработки проект будет принят. </div>\n",
    "        \n",
    "Залог успеха - работа сообща, взаимное уважение и работа в диалоге. Поэтому, помечай свои ответные комментарии на мои реплики заметным цветом или курсивом, так мне будет легче их отслеживать. Пожалуйста, не изменяй и не удаляй мои комментарии. Все это поможет выполнить повторную проверку быстрей.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Логистическая-регрессия\" data-toc-modified-id=\"Логистическая-регрессия-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Логистическая регрессия</a></span></li><li><span><a href=\"#LightGBM\" data-toc-modified-id=\"LightGBM-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>LightGBM</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "Вступление в работу очень важно, так человек, который смотрит твой проект (и на работе в том числе) будет сразу введен в курс дела. \n",
    "     \n",
    "    \n",
    " \n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет: \n",
    "   \n",
    "Вопросик, при желании можешь ответить )\n",
    "    \n",
    "    \n",
    "- а почему по твоему была выбрана метрика f1? \n",
    "    \n",
    "    \n",
    "- а что если бы нам было нужно найти как можно больше токсичных комментариев, в этом случаи на какую метрику мы бы ориентировались?\n",
    "    \n",
    "    \n",
    "- каким образом мы можем изменить функцию ошибки в модели, чтобы она максимизировала интересующую нас метрику (accuracy, f1, precision, roc-auc итп)?    \n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортирование необходимых библиотек:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import warnings\n",
    "import lightgbm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "Собираем все импорты в верхней части, чтобы легче было ориентироваться и добавлять новые по необходимости. \n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Совет:     \n",
    "    \n",
    "\n",
    "\n",
    "- кстати есть рекомендации PEP-8 при написании кода, в том числе и для импортов. Если интересно можешь почитать [тут](https://pythonworld.ru/osnovy/pep-8-rukovodstvo-po-napisaniyu-koda-na-python.html). Есть что поправить\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet','stopwords','punkt','averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чтение датасета:\n",
    "df = pd.read_csv('/datasets/toxic_comments.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "Если не знаешь - чтобы не было столбца  `Unnamed: 0` при чтении файла можно так:\n",
    "\n",
    "\n",
    "    pd.read_csv(..., index_col=0)\n",
    "\n",
    "    \n",
    "(`Unnamed: 0` появляется при не совсем корректном сохранении файла)    \n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# Рассмотрим общую информацию о данных:\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89.83878663 10.16121337]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Так как перед нами задача классификации не будет лишним взглянуть на баланс классов:\n",
    "plt.bar(x=['no_toxic', 'toxic'], height = (df['toxic'].value_counts() / df.shape[0] * 100), color='g')\n",
    "plt.title('Balance of classes')\n",
    "plt.ylabel('Доля')\n",
    "plt.grid()\n",
    "print((df['toxic'].value_counts() / df.shape[0] * 100).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не сложно заметить, что баланс классов сильно смещен в сторону позитивных комментариев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "Данные изучены. Небольшой EDA не помешает, так как это аналитический проект. \n",
    "\n",
    "\n",
    "Плюс за\n",
    "\n",
    "\n",
    "    \n",
    "-  проверку на сбалансированность \n",
    "\n",
    "\n",
    "\n",
    "- промужуточный вывод в конце раздела\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Ошибка ❌:\n",
    "\n",
    "\n",
    "Перед лематизацией рекомендую сделать очистку текста - Нам не нужны знаки пунктуации, цифры и не латинские буквы\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(text):\n",
    "    text = re.sub(r\"(?:\\n|\\r)\", \" \", text)\n",
    "    text = re.sub(r\"[^a-zA-Z ]+\", \"\", text).strip()\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "df['text'] = df['text'].apply(cleaning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "\n",
    "\n",
    "Исправление принято\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemm = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем словарь с частями речи:\n",
    "def get_pos_tag(word):\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    " \n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Лемматизация\n",
    "def get_word_text(corpus):\n",
    "  i = []\n",
    "  for sentence in corpus:\n",
    "    i.append(' '.join([lemm.lemmatize(w, get_pos_tag(w)) for w in nltk.word_tokenize(sentence)]))\n",
    "  return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus['text'] = corpus['text'].apply(lambda x: \" \". join(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daww he matches this background colour im seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man im really not trying to edit war its j...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i cant make any real suggestions on impro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits made under my userna...      0\n",
       "1  daww he matches this background colour im seem...      0\n",
       "2  hey man im really not trying to edit war its j...      0\n",
       "3  more i cant make any real suggestions on impro...      0\n",
       "4  you sir are my hero any chance you remember wh...      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits make under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>daww he match this background colour im seemin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man im really not try to edit war it just ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i cant make any real suggestion on improv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir be my hero any chance you remember wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits make under my userna...      0\n",
       "1  daww he match this background colour im seemin...      0\n",
       "2  hey man im really not try to edit war it just ...      0\n",
       "3  more i cant make any real suggestion on improv...      0\n",
       "4  you sir be my hero any chance you remember wha...      0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus['text'] = get_word_text(corpus['text'])\n",
    "corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "- Тобой найдены хорошие функции для лемитизации, не забыто о особенности WordNetLemmatizer (POS-теги) и применено корректно\n",
    "\n",
    "\n",
    "- Плюс за использование apply, неэффективные циклы нам ни к чему.\n",
    "\n",
    "\n",
    "- Да, всегда лучше проверить что получилось  в итоге, так всегда будет возможность поправить ошбку\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "- попробуй .progress_apply, делает что .apply, но еще и показывает на какой итерации находится процесс\n",
    "\n",
    "\n",
    "    \n",
    "- после очистки и лемитизации можно провести частотный анализ текста/[облако слов](https://habr.com/ru/post/517410/) - чтобы получить общее представление о тематике и о наиболее часто встерчаемых словах Кроме того графики, рисунки делают проект визуально интересней\n",
    "    \n",
    "    \n",
    "\n",
    "- все это можно было сделать с помощью SpaCy лемматизатором и прямо скажем как инстурмент он более удобен и универсален, можно [почитать](https://habr.com/ru/post/531940/)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Стопслова:\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(nltk_stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "Не забыли о стопсловах, они ни к чему и код побежит быстрей\n",
    "\n",
    "    \n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "Совет:     \n",
    "\n",
    "Вопросик:\n",
    "\n",
    "А стопслова важней убирать  когда мы используем TF-IDF, или когда используе обычный CountVectorizer? \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV3</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Ошибка ❌:\n",
    "\n",
    "\n",
    "\n",
    "вот это всё не нужно.  Закомментируй этот код\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Совет 🤔:\n",
    "\n",
    "\n",
    "Лишний код. Ещё и random_state  забыл\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Ошибка ❌:\n",
    "\n",
    "\n",
    "\n",
    "Не используешь random_state, в результате при каждом запуске кода Сплит будет разный, как следствие будут разные результаты. Тебе вообще этот код не нужен, dtlm ты используешь pipeline. \n",
    "    \n",
    "    \n",
    "Чтобы использовать правильно:\n",
    "    \n",
    "    \n",
    "1.    По-разному сделай название модели, пока у тебя они одинаковые: grid (grid_rf, grid_lr) \n",
    "    \n",
    "    \n",
    "2.    используй \n",
    "    \n",
    "    \n",
    "    lr_pred = grid_lr.best_estimator_.predict(features_valid)\n",
    "    \n",
    "\n",
    " \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "- random_state на месте\n",
    "\n",
    "\n",
    "- правильно разбил на 2 выборки (иногда студенты использующие GS разбивают на 3 датасета)\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "\n",
    "\n",
    "Совет: \n",
    "\n",
    "\n",
    "\n",
    "- Обрати внимание на аргумент stratify, он позволит сохранить изначальное распределение таргетов во всех новых датасетах.  Существующий дисбаланс никуда не денется, но в каждом датасете он будет одинаковым. [Почитать](https://pythonru.com/baza-znanij/sklearn-train-test-split) можно тут\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = corpus['text']\n",
    "target = corpus['toxic']\n",
    "features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.25, random_state=12345)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'clf__C': 5, 'clf__penalty': 'l1', 'clf__solver': 'liblinear'}\n",
      "0.7816466360548321\n"
     ]
    }
   ],
   "source": [
    "pipe_lr = Pipeline([('vect', CountVectorizer()),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                ('clf', LogisticRegression(random_state=12345))])\n",
    "\n",
    "grid_params_lr = [{'clf__penalty': ['l1', 'l2'],\n",
    "        'clf__C': range(5, 20, 1),\n",
    "        'clf__solver': ['liblinear']}]\n",
    "\n",
    "grid_lr = GridSearchCV(pipe_lr, grid_params_lr, scoring='f1', cv=3)\n",
    "grid_lr.fit(features_train, target_train)\n",
    "print(grid_lr.best_params_)\n",
    "print(grid_lr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=5, class_weight='balanced', random_state=12345)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=5, class_weight='balanced', random_state=12345)\n",
    "model.fit(train_features,train_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "\n",
    "\n",
    "- Не забываем при инициализации модели о random_state, иначе после каждого запуска какой у нас может быть разный результат\n",
    "\n",
    "\n",
    "    \n",
    "- test датасет используем в самом конце, когда тестируем лучшую модель \n",
    "    \n",
    "    \n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Успех:\n",
    "\n",
    "\n",
    "GridSearch + pipeline это уже другой уровень. Pipeline мало кто использует даже после совета, хотя он позволяет избежать утечки данных (особенно важно при использовании GridSearchCV/cross_val_score с предобработкой данных), и делает наш код лаконичней.\n",
    "    \n",
    "    \n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lgbm = Pipeline([('vect', CountVectorizer()),\n",
    "                   ('tfidf', TfidfTransformer()),\n",
    "                ('clf', lightgbm.LGBMClassifier(random_state=12345))])\n",
    "\n",
    "grid_params_lgbm = [{'clf__max_depth': range(5, 30, 5),\n",
    "        'clf__n_estimators': range(20, 100, 10)}]\n",
    "\n",
    "grid_lgbm = GridSearchCV(pipe_lgbm, grid_params_lgbm, scoring='f1', cv=3)\n",
    "grid_lgbm.fit(features_train, target_train)\n",
    "print(grid_lgbm.best_params_)\n",
    "print(grid_lgbm.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий студента</b></font>\n",
    "    Не очень понимаю почему получается такое большое значение best_score_ у модели леса, мне кажется это довольно странно с учетом того, что если дать этой модели тестовые данные, то значение метрики f1 для таких предсказаний будет очень маленьким, не очень понимаю почему так происходит.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV3</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Совет 🤔:\n",
    "\n",
    "\n",
    "Такого быть не должно, тем более с 'max_depth': 1, 'n_estimators': 1 (это значит у тебя дерево решений с пеньком - чепуха какая то). Пока непонятно почему.  Давай начнём с того ты сделаешь один train_test_split. А то для одной модели ты используешь один Сплит и pipeline, для другой используешь другой сплит без pipeline.  И непонятно почему ты обучаешь на 5000.\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "Вот схема:    \n",
    "    \n",
    "1 Сделал сплит\n",
    "    \n",
    "    \n",
    "    features = corpus['text']\n",
    "    target = corpus['toxic']\n",
    "    features_train, features_test, target_train, target_test = train_test_split(features, target, test_size=0.25, random_state=12345)   \n",
    "    \n",
    "    \n",
    "    \n",
    "2 обучил:\n",
    "    \n",
    "        grid_lr.fit(features_train, target_train)\n",
    "\n",
    "    \n",
    "    \n",
    "3 выбрал лучшую через .best_score_\n",
    "    \n",
    "    \n",
    "    \n",
    "4 Сделал прогноз для теста\n",
    "    \n",
    "    grid_lr.best_estimator_.predict(features_test)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV3</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Совет 🤔:\n",
    "\n",
    "Не стоит использовать деревянные модели, они медленные и не показывает высокий результат для данного датасета. Попробуй быструю модель. \n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Ошибка ❌:\n",
    "\n",
    "\n",
    "\n",
    "- У нас задача классификации. \n",
    "\n",
    "    \n",
    "- Когда делаешь инициализацию модели ставишь    random_state, иначе каждый раз результаты разные\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred = grid_lr.best_estimator_.predict(features_test)\n",
    "result = f1_score(lr_pred, target_test)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "\n",
    "А вот тут, в самом конце,  выбрав лучшую модель на валидации, проверяем ее на тестовом датасете - делаем финальное тестирование. И если лучшая модель выбранная на валидационной покажет на test результат хуже требуемого, мы начнем процесс моделирования сначала (а не будем такие - \"а давай попробуем на тесте модель которая на валидации не была лучшей, может она нам на test даст нужное качество\").         \n",
    "    \n",
    "Почему только лучшая?! Это делается для того, чтобы мы даже незначительным образом не \"подгонялись\" под тестовую выборку. Ведь на train модели обучаются, по валидиации подгоняются гиперпараметры. Эти данные модели \"знают\". А test (out-of-sample) это уже моделирование прогноза на реальных данных и ситуации когда у нас есть уже лучшая модель (в рельности у нас же не может быть несоклько прогнозов, что то в любом случаи надо выбирать). Вот поэтому такая двухуровневая проверка на подгонку. Кроме того использование мноих моделей с разными гиперпараметрами это тоже подгонка, поэтому выбирая одну и тестируя только ее, мы тем самым боремся с подгонкой через использование многих-многих моделей, когда результат хорош не потому что мы данные почистили хорошо, моделировали правильно итд итп, а потому что из многих моделей хоть какая то случайно \"сыграет\". \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изначально был проведен небольшой EDA, проведено сравнение баланса классов. После чего была проведена чистка от разделителей строк и заглавных символов С помощью TF-IDF векторайзера данные были подготовлены для обучения, после чего были обучены модели логистической регрессии и случайного леса, более хороший результат по показателю на валидации показала модель логисчтической регрессии. На тестовой выборке модель достигла требуемого результата."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "Успех 👍:\n",
    "\n",
    "Общий вывод  добавлен"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "Ошибка:\n",
    "\n",
    "В конце проекта принято кратко описывать все проделанные шаги и полученные результаты. Зачем это нужно - когда проект захочет посмотреть будущий работодатель, у него может не быть времени на подробный разбор кода. Вероятнее всего он бегло просмотрит код, но захочет изучить результат, который будет в общем выводе. Поэтому все же советую написать общий вывод пообьемней: добавить пару слов о данных, работе с ними, о моделях, метриках, чтобы общий вывод соответствовал твоей классной работе.\n",
    "\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюера</b></font>\n",
    "\n",
    "\n",
    "\n",
    "Марк, у тебя старательно выполненная работа, все четко, осмысленно. Некоторые пункты выполнены в большем чем требуется обьеме (pipeline) Выводы присутствуют\n",
    "\n",
    "\n",
    "Я оставил небольшие советы и вопросики (если есть время и желание можешь воспользоваться/ответить).\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "Обязательное к исправлению:\n",
    "\n",
    "\n",
    "\n",
    "- Не забываем об очистке текста\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- Когда используем Grid Search оценка на валидации это .best_score, по ней и сравниваем модели выбирая лучшую для теста, а на test датасете тестируем только лучшую модель (нарушена логика использования датасетов при моделировании)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- не забываем о random_state\n",
    "   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "Жду исправлений, для принятия проекта. Если какие то вопросы, то сразу спрашивай ) \n",
    "\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV2</b></font>\n",
    "\n",
    "Спасибо за работу!    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "Что осталось из красного:\n",
    "\n",
    "    \n",
    "    \n",
    "- У нас задача классификации, а не регрессии. random_state при инициализации модели Не забывай\n",
    "    \n",
    "    \n",
    "- Используй возможности GS+Pipeline когда делаешь прогноз (подсказал как). А так получается у тебя лишний код, а кроме того в этом лишнем коде у тебя нет random_state   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV3</b></font>\n",
    "\n",
    "   \n",
    "\n",
    "    \n",
    "- Марк, сделай для обоих моделей один train_test_split (Запутаться же можно в выборках и непонятно зачем ты это делаешь)\n",
    "\n",
    "\n",
    "    \n",
    "- В обоих случаях Используй pipeline,  зачем нам разные подходы, если ты отлично использовал pipeline\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "Вместе случайного леса используй модель LightGBM (к примеру). Глядишь и не будет несуразицы с \n",
    "    \n",
    "    \n",
    "    {'max_depth': 1, 'n_estimators': 1}\n",
    "    0.9034000000000001\n",
    "    \n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-info\">\n",
    "<font size=\"5\"><b>Комментарий ревьюераV4</b></font>\n",
    "\n",
    "Спасибо за работу!    \n",
    "\n",
    "    \n",
    "\n",
    "Красного нет, вопросов нет, значит все, пора принимать) Надеюсь мои советы и вопросики были полезны и в копилочку знаний упало что то новое, а проект стал лучше, и симпатичней.\n",
    "\n",
    "  \n",
    "Отличная работа Марк. Желаю успехов в дальнейшей учебе!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [ ]  Весь код выполняется без ошибок\n",
    "- [ ]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [ ]  Данные загружены и подготовлены\n",
    "- [ ]  Модели обучены\n",
    "- [ ]  Значение метрики *F1* не меньше 0.75\n",
    "- [ ]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 7188,
    "start_time": "2023-02-03T22:40:25.449Z"
   },
   {
    "duration": 16805,
    "start_time": "2023-02-03T22:41:29.121Z"
   },
   {
    "duration": 204,
    "start_time": "2023-02-03T22:42:29.940Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-03T22:43:44.036Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-03T22:43:53.409Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-03T22:44:20.138Z"
   },
   {
    "duration": 134,
    "start_time": "2023-02-03T22:44:42.945Z"
   },
   {
    "duration": 676,
    "start_time": "2023-02-03T22:45:04.757Z"
   },
   {
    "duration": 158,
    "start_time": "2023-02-03T22:45:09.385Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-03T22:45:35.278Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-03T22:45:47.244Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-03T22:45:51.828Z"
   },
   {
    "duration": 49,
    "start_time": "2023-02-03T22:46:17.660Z"
   },
   {
    "duration": 56,
    "start_time": "2023-02-03T22:46:30.137Z"
   },
   {
    "duration": 149,
    "start_time": "2023-02-03T22:46:36.463Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-03T22:47:21.680Z"
   },
   {
    "duration": 147,
    "start_time": "2023-02-03T22:49:15.294Z"
   },
   {
    "duration": 39,
    "start_time": "2023-02-03T22:49:39.343Z"
   },
   {
    "duration": 106,
    "start_time": "2023-02-03T22:50:00.179Z"
   },
   {
    "duration": 16,
    "start_time": "2023-02-03T22:50:24.091Z"
   },
   {
    "duration": 121,
    "start_time": "2023-02-03T22:50:41.740Z"
   },
   {
    "duration": 54,
    "start_time": "2023-02-03T22:51:07.309Z"
   },
   {
    "duration": 101,
    "start_time": "2023-02-03T22:51:11.502Z"
   },
   {
    "duration": 107,
    "start_time": "2023-02-03T22:51:22.868Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-03T22:53:53.327Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-03T22:54:00.289Z"
   },
   {
    "duration": 120,
    "start_time": "2023-02-03T22:54:35.717Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-03T22:54:42.633Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-03T22:55:02.298Z"
   },
   {
    "duration": 83,
    "start_time": "2023-02-03T22:55:17.804Z"
   },
   {
    "duration": 83,
    "start_time": "2023-02-03T22:55:37.163Z"
   },
   {
    "duration": 48,
    "start_time": "2023-02-03T22:55:59.543Z"
   },
   {
    "duration": 80,
    "start_time": "2023-02-03T22:56:11.577Z"
   },
   {
    "duration": 86,
    "start_time": "2023-02-03T22:56:18.252Z"
   },
   {
    "duration": 99,
    "start_time": "2023-02-03T22:58:04.764Z"
   },
   {
    "duration": 95,
    "start_time": "2023-02-03T22:58:41.879Z"
   },
   {
    "duration": 188,
    "start_time": "2023-02-03T22:58:57.815Z"
   },
   {
    "duration": 92,
    "start_time": "2023-02-03T22:59:08.949Z"
   },
   {
    "duration": 98,
    "start_time": "2023-02-03T22:59:35.850Z"
   },
   {
    "duration": 93,
    "start_time": "2023-02-03T22:59:38.933Z"
   },
   {
    "duration": 88,
    "start_time": "2023-02-03T22:59:42.831Z"
   },
   {
    "duration": 94,
    "start_time": "2023-02-03T23:00:12.544Z"
   },
   {
    "duration": 92,
    "start_time": "2023-02-03T23:00:17.414Z"
   },
   {
    "duration": 97,
    "start_time": "2023-02-03T23:00:21.124Z"
   },
   {
    "duration": 97,
    "start_time": "2023-02-03T23:00:37.344Z"
   },
   {
    "duration": 91,
    "start_time": "2023-02-03T23:00:41.238Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-03T23:00:46.329Z"
   },
   {
    "duration": 108,
    "start_time": "2023-02-03T23:00:49.781Z"
   },
   {
    "duration": 97,
    "start_time": "2023-02-03T23:01:02.317Z"
   },
   {
    "duration": 97,
    "start_time": "2023-02-03T23:01:13.002Z"
   },
   {
    "duration": 91,
    "start_time": "2023-02-03T23:01:16.477Z"
   },
   {
    "duration": 94,
    "start_time": "2023-02-03T23:01:25.152Z"
   },
   {
    "duration": 56,
    "start_time": "2023-02-03T23:01:27.547Z"
   },
   {
    "duration": 86,
    "start_time": "2023-02-03T23:01:30.020Z"
   },
   {
    "duration": 1290,
    "start_time": "2023-02-03T23:03:23.482Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-03T23:03:55.309Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-04T00:04:02.513Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-04T00:05:14.735Z"
   },
   {
    "duration": 2,
    "start_time": "2023-02-04T00:05:54.242Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-04T00:07:14.905Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-04T00:09:30.931Z"
   },
   {
    "duration": 1180,
    "start_time": "2023-02-04T00:09:32.012Z"
   },
   {
    "duration": 41,
    "start_time": "2023-02-04T00:09:48.759Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-04T00:10:10.708Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-04T00:10:11.018Z"
   },
   {
    "duration": 1159,
    "start_time": "2023-02-04T00:10:12.538Z"
   },
   {
    "duration": 35,
    "start_time": "2023-02-04T00:10:13.700Z"
   },
   {
    "duration": 1821,
    "start_time": "2023-02-04T00:10:55.064Z"
   },
   {
    "duration": 27,
    "start_time": "2023-02-04T00:11:01.264Z"
   },
   {
    "duration": 1291213,
    "start_time": "2023-02-04T00:11:16.336Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-04T00:38:04.972Z"
   },
   {
    "duration": 1150,
    "start_time": "2023-02-04T00:38:07.496Z"
   },
   {
    "duration": 1269190,
    "start_time": "2023-02-04T00:38:09.814Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-04T01:03:23.697Z"
   },
   {
    "duration": 29,
    "start_time": "2023-02-04T01:03:50.750Z"
   },
   {
    "duration": 12632,
    "start_time": "2023-02-04T01:05:14.985Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-04T01:05:38.476Z"
   },
   {
    "duration": 32,
    "start_time": "2023-02-04T01:06:36.275Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-04T01:07:03.521Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-04T01:07:39.068Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T01:58:27.348Z"
   },
   {
    "duration": 1875,
    "start_time": "2023-02-04T15:25:24.731Z"
   },
   {
    "duration": 1368,
    "start_time": "2023-02-04T15:25:28.625Z"
   },
   {
    "duration": 2272,
    "start_time": "2023-02-04T15:25:29.995Z"
   },
   {
    "duration": 25,
    "start_time": "2023-02-04T15:25:32.269Z"
   },
   {
    "duration": 27,
    "start_time": "2023-02-04T15:25:36.202Z"
   },
   {
    "duration": 97,
    "start_time": "2023-02-04T15:25:36.353Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-04T15:25:38.257Z"
   },
   {
    "duration": 286,
    "start_time": "2023-02-04T15:25:39.649Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-04T15:26:17.530Z"
   },
   {
    "duration": 1169,
    "start_time": "2023-02-04T15:26:19.194Z"
   },
   {
    "duration": 688,
    "start_time": "2023-02-04T15:26:20.526Z"
   },
   {
    "duration": 35,
    "start_time": "2023-02-04T15:26:21.215Z"
   },
   {
    "duration": 109,
    "start_time": "2023-02-04T15:26:21.252Z"
   },
   {
    "duration": 7,
    "start_time": "2023-02-04T15:26:23.665Z"
   },
   {
    "duration": 2205,
    "start_time": "2023-02-04T15:26:24.545Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-04T15:26:38.953Z"
   },
   {
    "duration": 1682,
    "start_time": "2023-02-04T15:27:59.088Z"
   },
   {
    "duration": 6,
    "start_time": "2023-02-04T15:28:00.772Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-04T15:28:01.999Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-04T15:28:04.784Z"
   },
   {
    "duration": 909,
    "start_time": "2023-02-04T15:28:10.081Z"
   },
   {
    "duration": 1746,
    "start_time": "2023-02-04T15:29:31.959Z"
   },
   {
    "duration": 1548,
    "start_time": "2023-02-04T15:29:35.055Z"
   },
   {
    "duration": 2554,
    "start_time": "2023-02-04T15:30:01.201Z"
   },
   {
    "duration": 1880,
    "start_time": "2023-02-04T15:30:06.638Z"
   },
   {
    "duration": 2169,
    "start_time": "2023-02-04T15:30:08.520Z"
   },
   {
    "duration": 29,
    "start_time": "2023-02-04T15:30:10.690Z"
   },
   {
    "duration": 87,
    "start_time": "2023-02-04T15:30:12.767Z"
   },
   {
    "duration": 2123,
    "start_time": "2023-02-04T15:30:14.774Z"
   },
   {
    "duration": 1691,
    "start_time": "2023-02-04T15:30:17.671Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-04T15:30:19.847Z"
   },
   {
    "duration": 99,
    "start_time": "2023-02-04T15:30:53.870Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-04T15:30:54.396Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-04T15:30:55.783Z"
   },
   {
    "duration": 731,
    "start_time": "2023-02-04T15:30:57.618Z"
   },
   {
    "duration": 584,
    "start_time": "2023-02-04T15:31:17.738Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-04T15:47:04.790Z"
   },
   {
    "duration": 2066,
    "start_time": "2023-02-04T15:48:05.068Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-04T15:48:11.864Z"
   },
   {
    "duration": 1731,
    "start_time": "2023-02-04T15:48:11.869Z"
   },
   {
    "duration": 2204,
    "start_time": "2023-02-04T15:48:13.602Z"
   },
   {
    "duration": 24,
    "start_time": "2023-02-04T15:48:15.808Z"
   },
   {
    "duration": 97,
    "start_time": "2023-02-04T15:48:15.834Z"
   },
   {
    "duration": 2184,
    "start_time": "2023-02-04T15:48:15.932Z"
   },
   {
    "duration": 1712,
    "start_time": "2023-02-04T15:48:18.117Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-04T15:48:19.831Z"
   },
   {
    "duration": 121,
    "start_time": "2023-02-04T15:48:19.837Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T15:48:19.960Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T15:48:19.961Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T15:48:19.962Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T15:48:19.963Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T15:48:19.964Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T15:48:19.966Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T15:48:19.966Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T15:48:19.967Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T15:48:19.969Z"
   },
   {
    "duration": 12,
    "start_time": "2023-02-04T15:49:31.676Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-04T15:49:34.731Z"
   },
   {
    "duration": 1018,
    "start_time": "2023-02-04T15:49:34.737Z"
   },
   {
    "duration": 672,
    "start_time": "2023-02-04T15:49:35.756Z"
   },
   {
    "duration": 27,
    "start_time": "2023-02-04T15:49:36.429Z"
   },
   {
    "duration": 93,
    "start_time": "2023-02-04T15:49:36.458Z"
   },
   {
    "duration": 2231,
    "start_time": "2023-02-04T15:49:36.553Z"
   },
   {
    "duration": 2533,
    "start_time": "2023-02-04T15:49:58.865Z"
   },
   {
    "duration": 1459,
    "start_time": "2023-02-04T15:50:01.400Z"
   },
   {
    "duration": 2254,
    "start_time": "2023-02-04T15:50:02.861Z"
   },
   {
    "duration": 29,
    "start_time": "2023-02-04T15:50:05.116Z"
   },
   {
    "duration": 116,
    "start_time": "2023-02-04T15:50:05.148Z"
   },
   {
    "duration": 2166,
    "start_time": "2023-02-04T15:50:05.265Z"
   },
   {
    "duration": 1711,
    "start_time": "2023-02-04T15:50:07.434Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-04T15:50:09.146Z"
   },
   {
    "duration": 118,
    "start_time": "2023-02-04T15:50:09.165Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T15:50:09.284Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T15:50:09.285Z"
   },
   {
    "duration": 1,
    "start_time": "2023-02-04T15:50:09.286Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T15:50:09.287Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T15:50:09.288Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T15:50:09.289Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T15:50:09.290Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T15:50:09.291Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T15:50:09.292Z"
   },
   {
    "duration": 693,
    "start_time": "2023-02-04T15:50:19.368Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-04T15:50:24.763Z"
   },
   {
    "duration": 63,
    "start_time": "2023-02-04T15:50:35.714Z"
   },
   {
    "duration": 6106,
    "start_time": "2023-02-04T15:50:37.652Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-04T15:50:44.745Z"
   },
   {
    "duration": 179718,
    "start_time": "2023-02-04T15:51:30.932Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-04T15:54:30.652Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T15:54:30.664Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T15:54:30.666Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-04T15:54:30.667Z"
   },
   {
    "duration": 1834,
    "start_time": "2023-02-04T15:59:24.670Z"
   },
   {
    "duration": 1162,
    "start_time": "2023-02-04T15:59:27.822Z"
   },
   {
    "duration": 2475,
    "start_time": "2023-02-04T15:59:28.987Z"
   },
   {
    "duration": 29,
    "start_time": "2023-02-04T15:59:31.464Z"
   },
   {
    "duration": 104,
    "start_time": "2023-02-04T15:59:36.026Z"
   },
   {
    "duration": 2189,
    "start_time": "2023-02-04T15:59:39.877Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-04T15:59:43.198Z"
   },
   {
    "duration": 2,
    "start_time": "2023-02-04T15:59:44.063Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-04T15:59:45.167Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-04T15:59:50.276Z"
   },
   {
    "duration": 614,
    "start_time": "2023-02-04T15:59:53.581Z"
   },
   {
    "duration": 74,
    "start_time": "2023-02-04T15:59:55.263Z"
   },
   {
    "duration": 29,
    "start_time": "2023-02-04T16:00:23.027Z"
   },
   {
    "duration": 48,
    "start_time": "2023-02-05T01:01:39.755Z"
   },
   {
    "duration": 1774,
    "start_time": "2023-02-05T01:01:48.507Z"
   },
   {
    "duration": 1895,
    "start_time": "2023-02-05T01:01:51.313Z"
   },
   {
    "duration": 2505,
    "start_time": "2023-02-05T01:01:53.211Z"
   },
   {
    "duration": 34,
    "start_time": "2023-02-05T01:01:55.717Z"
   },
   {
    "duration": 123,
    "start_time": "2023-02-05T01:01:55.754Z"
   },
   {
    "duration": 2630,
    "start_time": "2023-02-05T01:01:55.879Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-05T01:01:58.512Z"
   },
   {
    "duration": 14,
    "start_time": "2023-02-05T01:01:58.516Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-05T01:01:58.531Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-05T01:01:58.542Z"
   },
   {
    "duration": 825,
    "start_time": "2023-02-05T01:01:59.209Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-05T01:02:00.931Z"
   },
   {
    "duration": 259,
    "start_time": "2023-02-05T01:02:01.568Z"
   },
   {
    "duration": 1100178,
    "start_time": "2023-02-05T01:20:31.543Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-05T01:38:51.723Z"
   },
   {
    "duration": 42,
    "start_time": "2023-02-05T01:38:51.730Z"
   },
   {
    "duration": 5035,
    "start_time": "2023-02-05T01:38:51.774Z"
   },
   {
    "duration": 6284,
    "start_time": "2023-02-05T01:38:56.810Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-05T01:39:03.096Z"
   },
   {
    "duration": 40,
    "start_time": "2023-02-05T01:39:03.100Z"
   },
   {
    "duration": 1500507,
    "start_time": "2023-02-05T01:39:03.142Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-05T02:04:03.650Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-05T02:04:03.652Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-05T02:04:03.653Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-05T02:04:03.654Z"
   },
   {
    "duration": 0,
    "start_time": "2023-02-05T02:04:03.655Z"
   },
   {
    "duration": 1494776,
    "start_time": "2023-02-05T02:13:09.100Z"
   },
   {
    "duration": 51323,
    "start_time": "2023-02-05T03:06:57.917Z"
   },
   {
    "duration": 44,
    "start_time": "2023-02-05T03:07:58.950Z"
   },
   {
    "duration": 11,
    "start_time": "2023-02-05T03:08:34.965Z"
   },
   {
    "duration": 4246403,
    "start_time": "2023-02-05T03:09:27.916Z"
   },
   {
    "duration": 75,
    "start_time": "2023-02-05T09:48:35.907Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-05T09:49:02.425Z"
   },
   {
    "duration": 592,
    "start_time": "2023-02-05T09:49:19.969Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-05T09:49:29.209Z"
   },
   {
    "duration": 286,
    "start_time": "2023-02-05T09:49:36.800Z"
   },
   {
    "duration": 16,
    "start_time": "2023-02-05T09:51:16.984Z"
   },
   {
    "duration": 116,
    "start_time": "2023-02-05T09:52:12.527Z"
   },
   {
    "duration": 86,
    "start_time": "2023-02-05T09:53:54.781Z"
   },
   {
    "duration": 88,
    "start_time": "2023-02-05T09:54:01.364Z"
   },
   {
    "duration": 97,
    "start_time": "2023-02-05T09:55:04.293Z"
   },
   {
    "duration": 23,
    "start_time": "2023-02-05T09:55:50.005Z"
   },
   {
    "duration": 2190,
    "start_time": "2023-02-05T09:59:14.752Z"
   },
   {
    "duration": 608,
    "start_time": "2023-02-05T09:59:22.754Z"
   },
   {
    "duration": 133,
    "start_time": "2023-02-05T09:59:32.970Z"
   },
   {
    "duration": 25,
    "start_time": "2023-02-05T09:59:34.994Z"
   },
   {
    "duration": 3676,
    "start_time": "2023-02-05T09:59:58.993Z"
   },
   {
    "duration": 139,
    "start_time": "2023-02-05T10:00:05.753Z"
   },
   {
    "duration": 32,
    "start_time": "2023-02-05T10:00:08.434Z"
   },
   {
    "duration": 2380,
    "start_time": "2023-02-05T10:00:20.375Z"
   },
   {
    "duration": 121,
    "start_time": "2023-02-05T10:02:24.888Z"
   },
   {
    "duration": 27,
    "start_time": "2023-02-05T10:02:27.168Z"
   },
   {
    "duration": 29,
    "start_time": "2023-02-05T10:02:28.919Z"
   },
   {
    "duration": 2344,
    "start_time": "2023-02-05T10:02:31.832Z"
   },
   {
    "duration": 532,
    "start_time": "2023-02-05T10:02:59.256Z"
   },
   {
    "duration": 119,
    "start_time": "2023-02-05T10:03:01.200Z"
   },
   {
    "duration": 35,
    "start_time": "2023-02-05T10:05:59.016Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-05T10:06:01.686Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-05T10:08:21.956Z"
   },
   {
    "duration": 174015,
    "start_time": "2023-02-05T10:09:49.523Z"
   },
   {
    "duration": 52,
    "start_time": "2023-02-05T10:12:58.026Z"
   },
   {
    "duration": 2674,
    "start_time": "2023-02-05T10:13:03.706Z"
   },
   {
    "duration": 2530,
    "start_time": "2023-02-05T10:13:13.914Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-05T10:14:08.472Z"
   },
   {
    "duration": 2,
    "start_time": "2023-02-05T10:14:09.747Z"
   },
   {
    "duration": 5794,
    "start_time": "2023-02-05T10:14:37.474Z"
   },
   {
    "duration": 1683,
    "start_time": "2023-02-05T10:14:46.562Z"
   },
   {
    "duration": 26,
    "start_time": "2023-02-05T10:15:02.712Z"
   },
   {
    "duration": 228924,
    "start_time": "2023-02-05T10:15:42.692Z"
   },
   {
    "duration": 4,
    "start_time": "2023-02-05T12:20:48.819Z"
   },
   {
    "duration": 552,
    "start_time": "2023-02-05T12:21:37.889Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-05T12:22:43.513Z"
   },
   {
    "duration": 1509177,
    "start_time": "2023-02-05T12:22:50.057Z"
   },
   {
    "duration": 51406,
    "start_time": "2023-02-05T13:07:10.549Z"
   },
   {
    "duration": 510,
    "start_time": "2023-02-05T13:08:40.401Z"
   },
   {
    "duration": 130,
    "start_time": "2023-02-05T13:08:46.747Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-05T13:08:48.482Z"
   },
   {
    "duration": 1725,
    "start_time": "2023-02-05T13:08:50.089Z"
   },
   {
    "duration": 18,
    "start_time": "2023-02-05T13:08:59.481Z"
   },
   {
    "duration": 1740,
    "start_time": "2023-02-05T13:46:15.236Z"
   },
   {
    "duration": 121,
    "start_time": "2023-02-05T13:46:28.265Z"
   },
   {
    "duration": 1816,
    "start_time": "2023-02-05T13:46:29.212Z"
   },
   {
    "duration": 30,
    "start_time": "2023-02-05T13:47:02.708Z"
   },
   {
    "duration": 13,
    "start_time": "2023-02-05T13:47:12.029Z"
   },
   {
    "duration": 50155,
    "start_time": "2023-02-05T13:47:16.884Z"
   },
   {
    "duration": 124,
    "start_time": "2023-02-05T13:49:19.857Z"
   },
   {
    "duration": 466,
    "start_time": "2023-02-05T13:49:25.835Z"
   },
   {
    "duration": 121,
    "start_time": "2023-02-05T13:49:28.459Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-05T13:49:29.875Z"
   },
   {
    "duration": 21,
    "start_time": "2023-02-05T13:49:59.165Z"
   },
   {
    "duration": 1908,
    "start_time": "2023-02-05T13:50:37.826Z"
   },
   {
    "duration": 17,
    "start_time": "2023-02-05T13:50:48.573Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-05T13:50:53.835Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-05T13:51:17.228Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-05T13:51:22.363Z"
   },
   {
    "duration": 1673,
    "start_time": "2023-02-07T09:03:39.168Z"
   },
   {
    "duration": 132,
    "start_time": "2023-02-07T09:03:48.589Z"
   },
   {
    "duration": 10,
    "start_time": "2023-02-07T09:03:53.750Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-07T09:03:59.411Z"
   },
   {
    "duration": 15,
    "start_time": "2023-02-07T09:03:59.418Z"
   },
   {
    "duration": 3220,
    "start_time": "2023-02-07T09:03:59.435Z"
   },
   {
    "duration": 2516,
    "start_time": "2023-02-07T09:04:02.657Z"
   },
   {
    "duration": 29,
    "start_time": "2023-02-07T09:04:05.175Z"
   },
   {
    "duration": 120,
    "start_time": "2023-02-07T09:04:05.206Z"
   },
   {
    "duration": 2520,
    "start_time": "2023-02-07T09:04:05.328Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-07T09:04:07.850Z"
   },
   {
    "duration": 9,
    "start_time": "2023-02-07T09:04:07.856Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-07T09:04:07.867Z"
   },
   {
    "duration": 16,
    "start_time": "2023-02-07T09:04:07.873Z"
   },
   {
    "duration": 722,
    "start_time": "2023-02-07T09:04:07.891Z"
   },
   {
    "duration": 8,
    "start_time": "2023-02-07T09:04:08.615Z"
   },
   {
    "duration": 270,
    "start_time": "2023-02-07T09:04:08.625Z"
   },
   {
    "duration": 1112829,
    "start_time": "2023-02-07T09:04:08.896Z"
   },
   {
    "duration": 5,
    "start_time": "2023-02-07T09:22:41.727Z"
   },
   {
    "duration": 42,
    "start_time": "2023-02-07T09:22:41.744Z"
   },
   {
    "duration": 5072,
    "start_time": "2023-02-07T09:22:41.787Z"
   },
   {
    "duration": 6304,
    "start_time": "2023-02-07T09:22:46.861Z"
   },
   {
    "duration": 3,
    "start_time": "2023-02-07T09:22:53.167Z"
   },
   {
    "duration": 48,
    "start_time": "2023-02-07T09:22:53.171Z"
   },
   {
    "duration": 1422271,
    "start_time": "2023-02-07T09:22:53.221Z"
   },
   {
    "duration": 54163,
    "start_time": "2023-02-07T09:46:35.494Z"
   },
   {
    "duration": 282029,
    "start_time": "2023-02-07T12:59:17.043Z"
   },
   {
    "duration": 488,
    "start_time": "2023-02-07T13:03:59.074Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
